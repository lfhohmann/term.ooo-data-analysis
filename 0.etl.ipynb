{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Performing ETL on [Term.ooo](https://term.ooo) game** *(Brazilian Portuguese variant of [Wordle](https://www.nytimes.com/games/wordle/index.html))*\n",
    "\n",
    "Before we start, let's manually look into the source code for the variables where each words `list` is stored.\n",
    "\n",
    "###############################################################################<br>\n",
    "1st `list`:\n",
    "\n",
    "```js script\n",
    " 4352 >>>     Kf = new Set([\n",
    " 4353 >>>         \"ababa\",\n",
    " 4354 >>>         \"abacá\",\n",
    " 4355 >>>         \"abada\",\n",
    " 4356 >>>         \"abade\",\n",
    " 4357 >>>         \"abado\",\n",
    "                     ˄\n",
    "                     ˅\n",
    "13494 >>>         \"úropo\",\n",
    "13495 >>>         \"úsnea\",\n",
    "13496 >>>         \"úvico\",\n",
    "13497 >>>         \"úvido\",\n",
    "13498 >>>         \"úvula\",\n",
    "13499 >>>     ]),\n",
    "```\n",
    "###############################################################################<br>\n",
    "2nd `list`: \n",
    "\n",
    "```js script\n",
    "13500 >>>    Xf = {\n",
    "13501 >>>        abaca: \"abacá\",\n",
    "13502 >>>        abara: \"abará\",\n",
    "13503 >>>        abare: \"abaré\",\n",
    "13504 >>>        abebe: \"abebé\",\n",
    "13505 >>>        abece: \"abecê\",\n",
    "                           ˄\n",
    "                           ˅\n",
    "15638 >>>        uteis: \"úteis\",\n",
    "15639 >>>        utero: \"útero\",\n",
    "15640 >>>        uvico: \"úvico\",\n",
    "15641 >>>        uvido: \"úvido\",\n",
    "15642 >>>        uvula: \"úvula\",\n",
    "15643 >>>    },\n",
    "```\n",
    "\n",
    "################################################################################<br>\n",
    "3rd `list`: \n",
    "\n",
    "```js script\n",
    "15644 >>>    Zf = [\n",
    "15645 >>>        \"termo\",\n",
    "15646 >>>        \"suíte\",\n",
    "15647 >>>        \"ávido\",\n",
    "15648 >>>        \"festa\",\n",
    "15649 >>>        \"bebia\",\n",
    "                    ˄\n",
    "                    ˅\n",
    "17083 >>>        \"sósia\",\n",
    "17084 >>>        \"local\",\n",
    "17085 >>>        \"gemer\",\n",
    "17086 >>>        \"saber\",\n",
    "17087 >>>        \"visar\",\n",
    "17088 >>>    ],\n",
    "```\n",
    "\n",
    "Analysing the entire code *(**termo.js** file)*, we can find 3 lists of words. Apparently, there is a **valid guesses** `list`, a **valid_answers** `list` and a `dict/map` of **words with accents** to **words without accents**.\n",
    "\n",
    "We can see that the words are stored in variables called `Kf`, `Xf` and `Zf`, respectively. They are written over multiple lines of code.\n",
    "\n",
    "So, let's extract them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unidecode\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_preview(words_lists: list) -> None:\n",
    "    \"\"\"Helper function to print a preview of each words lists and their respective length\"\"\"\n",
    "\n",
    "    # Iterate over each words list\n",
    "    for words_list in words_lists:\n",
    "\n",
    "        # Check if the words list is not empty\n",
    "        if words_list:\n",
    "            print(f\"first:\\t{words_list[:10]}\")     # Print the first words\n",
    "            print(f\"last:\\t{words_list[-10:]}\")     # Print the last words\n",
    "            print(f\"length:\\t{len(words_list)}\")    # Print the length of the words list\n",
    "            print()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the JavaScript source code as a `list` of lines and preview it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the source code\n",
    "filepath = f\"./data/0.src_code/termo.js\"\n",
    "\n",
    "with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "    src_code = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################################################################\n",
      "FIRST LINES:\n",
      "\tfunction a(a, e) {\n",
      "\t    var o = Object.keys(a);\n",
      "\t    if (Object.getOwnPropertySymbols) {\n",
      "\t        var r = Object.getOwnPropertySymbols(a);\n",
      "\t        e &&\n",
      "\t            (r = r.filter(function (e) {\n",
      "\t                return Object.getOwnPropertyDescriptor(a, e).enumerable;\n",
      "\t            })),\n",
      "\t            o.push.apply(o, r);\n",
      "\t    }\n",
      "########################################################################################################################\n",
      "LAST LINES:\n",
      "\t                                })\n",
      "\t                                .join(\", \")\n",
      "\t                        )\n",
      "\t                    ),\n",
      "\t                Dh(1).then(function () {\n",
      "\t                    dx() || (xw.header.showBar(), gx(1));\n",
      "\t                }));\n",
      "\t        })(a, Fx);\n",
      "\t    for (var n = 0, s = a; n < s.length; n++) s[n].newLine();\n",
      "\t});\n",
      "########################################################################################################################\n",
      "TOTAL LENGTH: 22494\n"
     ]
    }
   ],
   "source": [
    "# Preview the source code\n",
    "print(\"#\" * 120)\n",
    "print(\"FIRST LINES:\")\n",
    "\n",
    "for line in src_code[:10]:\n",
    "    print(f\"\\t{line}\")\n",
    "\n",
    "print(\"#\" * 120)\n",
    "print(\"LAST LINES:\")\n",
    "\n",
    "for line in src_code[-10:]:\n",
    "    print(f\"\\t{line}\")\n",
    "\n",
    "print(\"#\" * 120)\n",
    "print(f\"TOTAL LENGTH: {len(src_code)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the words\n",
    "\n",
    "+ We can detect their start based on their variable name and their opening char: `'['` or `'{'`\n",
    "+ We can detect their end based on their closing char: `']'` or `'}'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first:\t['ababa', 'abaca', 'abada', 'abade', 'abado', 'abafa', 'abafe', 'abafo', 'abaju', 'abala']\n",
      "last:\t['unsia', 'uraco', 'urano', 'urceo', 'urico', 'uropo', 'usnea', 'uvico', 'uvido', 'uvula']\n",
      "length:\t9147\n",
      "\n",
      "first:\t['termo', 'suite', 'avido', 'festa', 'bebia', 'honra', 'ouvir', 'pesco', 'fungo', 'pagam']\n",
      "last:\t['quica', 'aviao', 'retro', 'dores', 'credo', 'hinos', 'capim', 'tango', 'voces', 'jurar']\n",
      "length:\t1443\n",
      "\n",
      "first:\t['abaca', 'abara', 'abare', 'abebe', 'abece', 'abede', 'abico', 'abobo', 'abofe', 'aboco']\n",
      "last:\t['urano', 'urceo', 'urico', 'uropo', 'usnea', 'uteis', 'utero', 'uvico', 'uvido', 'uvula']\n",
      "length:\t2142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_words_from_list(src_code: list, var_name: str, opening_char: str, closing_char: str) -> list:\n",
    "    \"\"\"Function to extract words from a list in the source code\"\"\"\n",
    "\n",
    "    # Init variables\n",
    "    words_list = []     # Output list of words\n",
    "    store_words = False # Flag to wheter store words or not\n",
    "\n",
    "    # Iterate over the source code's lines\n",
    "    for line in src_code:\n",
    "        \n",
    "        # If store_words flag is set, find words in the line\n",
    "        if store_words:\n",
    "            result = re.findall(r\"\\w+\", line)\n",
    "\n",
    "            # Check if the RegEx result contains words\n",
    "            if len(result):\n",
    "\n",
    "                # Grab the first word\n",
    "                # Remove accented and special characters, convert it to lowercase\n",
    "                # And add it to the words list\n",
    "                words_list.append(unidecode.unidecode(result[0]).lower())\n",
    "        \n",
    "        # If line contains the variable name and the opening char, set the flag to store words\n",
    "        if var_name in line and opening_char in line:\n",
    "            store_words = True\n",
    "\n",
    "        # If line contains the closing char, set the flag to not store words\n",
    "        if closing_char in line:\n",
    "            store_words = False\n",
    "\n",
    "    # Return the output words list\n",
    "    return words_list\n",
    "\n",
    "# Extract each words list\n",
    "words_lists = [None] * 3\n",
    "\n",
    "words_lists[0] = extract_words_from_list(src_code=src_code, var_name=\"Kf =\", opening_char=\"[\", closing_char=\"]\")\n",
    "words_lists[1] = extract_words_from_list(src_code=src_code, var_name=\"Zf =\", opening_char=\"[\", closing_char=\"]\")\n",
    "words_lists[2] = extract_words_from_list(src_code=src_code, var_name=\"Xf =\", opening_char=\"{\", closing_char=\"}\")\n",
    "\n",
    "# Print the words lists previews\n",
    "print_preview(words_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discarding duplicates\n",
    "\n",
    "Technically, it's very likely that the words contained in the `dict/map` *(3rd list)* object are the same ones in either the **valid guesses** or **valid answers** `lists` *(first 2 lists)*.\n",
    "\n",
    "Let's make sure all words in the `dict/map` object are not in either one of the 2 other lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All words are in either one of the first 2 lists\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the 3rd words list\n",
    "for word in words_lists[2]:\n",
    "\n",
    "    # If word not in either 2 first lists, print message and break\n",
    "    if word not in words_lists[0] and word not in words_lists[1]:\n",
    "        print(f\"The {word} is not in any of the first 2 lists\")\n",
    "        break\n",
    "\n",
    "# If loop is not broken, print message\n",
    "else:\n",
    "    print(\"All words are in either one of the first 2 lists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, there are no new words in the 3rd list, so we can discard it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first:\t['ababa', 'abaca', 'abada', 'abade', 'abado', 'abafa', 'abafe', 'abafo', 'abaju', 'abala']\n",
      "last:\t['unsia', 'uraco', 'urano', 'urceo', 'urico', 'uropo', 'usnea', 'uvico', 'uvido', 'uvula']\n",
      "length:\t9147\n",
      "\n",
      "first:\t['termo', 'suite', 'avido', 'festa', 'bebia', 'honra', 'ouvir', 'pesco', 'fungo', 'pagam']\n",
      "last:\t['quica', 'aviao', 'retro', 'dores', 'credo', 'hinos', 'capim', 'tango', 'voces', 'jurar']\n",
      "length:\t1443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del words_lists[2]\n",
    "\n",
    "except:\n",
    "    print(\"There in no 3rd words list\\n\")\n",
    "\n",
    "print_preview(words_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure, there are no duplicated words inside each list. We are going to convert each `list` into a `set`, which will get rid of duplicates.\n",
    "\n",
    "Then, we will check if there are duplicates across both lists.\n",
    "\n",
    "And, finally, each `set` will be converted back to a `list`.\n",
    "\n",
    "*(Duplicated words would unbalance the probabilities of each word being randomly picked during the game execution)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated words across lists: []\n"
     ]
    }
   ],
   "source": [
    "words_lists[0] = set(words_lists[0])\n",
    "words_lists[1] = set(words_lists[1])\n",
    "\n",
    "print(f\"Duplicated words across lists: {list(words_lists[0] & words_lists[1])}\")\n",
    "\n",
    "words_lists[0] = list(words_lists[0])\n",
    "words_lists[1] = list(words_lists[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, no words are duplicated across lists.\n",
    "\n",
    "Now, taking into consideration that the **valid guesses** list will always be larger than the **valid answers** list, we can store them *(alphabetically sorted)* on `.csv` files.\n",
    "\n",
    "The words in the first list `words_lists[0]` are our **valid guesses** and the ones in the second list `words_lists[1]` are our **valid answers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(filepath: str, words: list) -> None:\n",
    "    \"\"\"Function to write a list of words to a csv file\"\"\"\n",
    "\n",
    "    df = pd.DataFrame(words, columns=[\"word\"])\n",
    "    df.to_csv(filepath, index=False)\n",
    "\n",
    "\n",
    "write_csv(f\"./data/1.raw/valid_guesses.csv\", sorted(words_lists[0]))\n",
    "write_csv(f\"./data/1.raw/valid_answers.csv\", sorted(words_lists[1]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
